<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Nebula Graph"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@NebulaGraph"><meta name=twitter:creator content="@NebulaGraph"><meta name=twitter:domain content="nebula-graph.io"><meta name=twitter:title content="Kubernetes 部署 Nebula 图数据库集群"><meta property="twitter:title" content="Kubernetes 部署 Nebula 图数据库集群"><meta name=twitter:description content="数据库容器化是最近的一大热点，Kubernetes 能给数据库带来故障恢复、存储管理、负载均衡、水平拓展等好处。而它在图数据库 Nebula Graph 中可以发挥什么作用呢？"><meta name=og:description content="数据库容器化是最近的一大热点，Kubernetes 能给数据库带来故障恢复、存储管理、负载均衡、水平拓展等好处。而它在图数据库 Nebula Graph 中可以发挥什么作用呢？"><meta name=twitter:image content="/nebula-website/cn/posts/how-to-deploy-nebula-graph-in-kubernetes/k8s_hu0a6e1f3f33419b63da06b9322f348a9b_139884_600x0_resize_box_2.png"><meta name=og:image content="/nebula-website/cn/posts/how-to-deploy-nebula-graph-in-kubernetes/k8s_hu0a6e1f3f33419b63da06b9322f348a9b_139884_600x0_resize_box_2.png"><meta name=description content="数据库容器化是最近的一大热点，Kubernetes 能给数据库带来故障恢复、存储管理、负载均衡、水平拓展等好处。而它在图数据库 Nebula Graph 中可以发挥什么作用呢？"><meta name=generator content="Hugo 0.65.3"><title>Kubernetes 部署 Nebula 图数据库集群</title><link rel="shortcut icon" href=/nebula-website/favicon.ico><link rel=stylesheet href=/nebula-website/css/bootstrap.min.css type=text/css><link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel=stylesheet type=text/css><link href="//fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic" rel=stylesheet type=text/css><link rel=stylesheet href=/nebula-website/font-awesome/css/font-awesome.min.css type=text/css><link rel=stylesheet href=/nebula-website/css/creative.css type=text/css><link rel=stylesheet href=/nebula-website/css/modals.css type=text/css><link rel=stylesheet href=/nebula-website/css/animate.min.css type=text/css><link rel=stylesheet href=/nebula-website/css/custom/index.css type=text/css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js></script><script src=https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js></script><![endif]--><script src=/nebula-website/js/jquery.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-60523578-5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-60523578-5');</script></head><body id=page-top><nav id=mainNav class="navbar navbar-default navbar-fixed-top"><div class=container-fluid><div class=navbar-header><div class=github-star><a class=github-button href=https://github.com/vesoft-inc/nebula data-icon=octicon-star data-show-count=true aria-label="Star vesoft-inc/nebula on GitHub">Star</a></div><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#bs-example-navbar-collapse-1>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class="navbar-brand page-scroll" href=/></a></div><div class="collapse navbar-collapse" id=bs-example-navbar-collapse-1><ul class="nav navbar-nav" id=nav><li class=github-star id=github-star><a class=github-button href=https://github.com/vesoft-inc/nebula data-size=large data-show-count=true aria-label="Star vesoft-inc/nebula on GitHub">Star</a></li><li><a href=https://docs.nebula-graph.io/ target=_blank>文档</a></li><li class=active><a href=/cn/posts target>博客</a></li><li><a href=https://discuss.nebula-graph.io/ target=_blank>论坛</a></li><li><a href=#contact_us target onclick=contactUsClick()>联系我们</a></li><li class="dropdown navbar-right"><a class=dropdown-toggle data-toggle=dropdown href=# role=button aria-haspopup=true aria-expanded=false><img src=/images/language120x120.png>
<span class=caret></span></a><ul class=dropdown-menu><li class=nav-item><a class=dropdown-item href=/en target>English</a></li><li class=nav-item><a class=dropdown-item href=/cn target>中文</a></li></ul></li><li id=navbar-right><a href=https://github.com/vesoft-inc/nebula-web-docker target=_blank>Nebula Studio</a></li></ul></div></div></nav><script>function contactUsClick(){$('html,body').animate({scrollTop:document.documentElement.scrollHeight},800)
return false;}</script><main id=top class=blog-detail><div class=wrapper><div class=inner><section class=blog-content><h1>Kubernetes 部署 Nebula 图数据库集群</h1><div class=blog-metas><div class=meta><img src=/images/writer.png width=16px height=16px>
<span>徐飞</span></div><div class=meta><img src=/images/calendar.png width=16px height=16px>
<span>2020-02-26</span></div><div class="tags meta"><img src=/images/tag.png width=16px height=16px>
<a href=/nebula-website/cn//tags/%E9%83%A8%E7%BD%B2>部署</a></div></div><h2 id=kubernetes-是什么>Kubernetes 是什么</h2><p>Kubernetes 是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效，Kubernetes 提供了应用部署，规划，更新，维护的一种机制。Kubernetes 在设计结构上定义了一系列的构建模块，其目的是为了提供一个可以<strong>部署、维护和扩展应用程序的机制</strong>，组成 Kubernetes 的组件设计概念为<strong>松耦合</strong>和<strong>可扩展</strong>的，这样可以使之满足多种不同的工作负载。可扩展性在很大程度上由 Kubernetes
API 提供，此 API 主要被作为扩展的内部组件以及 Kubernetes 上运行的容器来使用。</p><p><img src=https://nebula-blog.azureedge.net/nebula-blog/k8s01.png alt></p><p>Kubernetes 主要由以下几个核心组件组成：</p><ul><li><code>etcd</code>  保存了整个集群的状态</li><li><code>apiserver</code> 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制</li><li><code>controller manager</code> 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</li><li><code>scheduler</code> 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上</li><li><code>kubelet</code> 负责维护容器的生命周期，同时也负责 Volume和网络的管理</li><li><code>Container runtime</code> 负责镜像管理以及 Pod 和容器的真正运行（CRI）</li><li><code>kube-proxy</code> 负责为 Service 提供 cluster 内部的服务发现和负载均衡</li></ul><p>除了核心组件，还有一些推荐的 Add-ons：</p><ul><li><code>kube-dns</code> 负责为整个集群提供 DNS 服务</li><li><code>Ingress Controller</code> 为服务提供外网入口</li><li><code>Heapster</code> 提供资源监控</li><li><code>Dashboard</code> 提供 GUI</li><li><code>Federation</code> 提供跨可用区的集群</li><li><code>Fluentd-elasticsearch</code> 提供集群日志采集、存储与查询</li></ul><h2 id=kubernetes-和数据库>Kubernetes 和数据库</h2><p>数据库容器化是最近的一大热点，那么 Kubernetes 能为数据库带来什么好处呢？</p><ul><li><strong>故障恢复</strong>: Kubernetes 提供故障恢复的功能，数据库应用如果宕掉，Kubernetes 可以将其<strong>自动重启</strong>，或者将数据库实例迁移到集群中其他节点上</li><li><strong>存储管理</strong>: Kubernetes 提供了丰富的存储接入方案，数据库应用能<strong>透明地使用不同类型的存储系统</strong></li><li><strong>负载均衡</strong>: Kubernetes Service 提供负载均衡功能，能将外部访问平摊给不同的数据库实例副本上</li><li><strong>水平拓展</strong>: Kubernetes 可以根据当前数据库集群的资源利用率情况，缩放副本数目，从而提升资源的利用率</li></ul><p>目前很多数据库，如：MySQL，MongoDB 和 TiDB 在 Kubernetes 集群中都能运行很良好。</p><h2 id=nebula-graph在kubernetes中的实践>Nebula Graph在Kubernetes中的实践</h2><p>Nebula Graph 是一个分布式的开源图数据库，主要组件有：Query Engine 的 graphd，数据存储的 storaged，和元数据的 meted。在 Kubernetes 实践过程中，它主要给图数据库 Nebula Graph 带来了以下的好处：</p><ul><li>Kubernetes 能分摊 nebula graphd，metad 和 storaged 不副本之间的负载。graphd，metad 和 storaged 可以通过 Kubernetes 的域名服务自动发现彼此。</li><li>通过 storageclass，pvc 和 pv 可以屏蔽底层存储细节，无论使用本地卷还是云盘，Kubernetes 均可以屏蔽这些细节。</li><li>通过 Kubernetes 可以在几秒内成功部署一套 Nebula 集群，Kubernetes 也可以无感知地实现 Nebula 集群的升级。</li><li>Nebula 集群通过 Kubernetes 可以做到自我恢复，单体副本 crash，Kubernetes 可以重新将其拉起，无需运维人员介入。</li><li>Kubernetes 可以根据当前 Nebula 集群的资源利用率情况水平伸缩 Nebula 集群，从而提供集群的性能。</li></ul><p>下面来讲解下具体的实践内容。</p><h3 id=集群部署>集群部署</h3><h4 id=硬件和软件要求>硬件和软件要求</h4><p>这里主要罗列下本文部署涉及到的机器、操作系统参数</p><ul><li>操作系统使用的 CentOS-7.6.1810 x86_64</li><li>虚拟机配置<ul><li>4 CPU</li><li>8G 内存</li><li>50G 系统盘</li><li>50G 数据盘A</li><li>50G 数据盘B</li></ul></li><li>Kubernetes 集群版本 v1.16</li><li>Nebula 版本为 v1.0.0-rc3</li><li>使用本地 PV 作为数据存储</li></ul><h4 id=kubernetes-集群规划>kubernetes 集群规划</h4><p>以下为集群清单</p><table><thead><tr><th>服务器 IP</th><th>nebula 实例</th><th>role</th></tr></thead><tbody><tr><td>192.168.0.1</td><td></td><td>k8s-master</td></tr><tr><td>192.168.0.2</td><td>graphd, metad-0, storaged-0</td><td>k8s-slave</td></tr><tr><td>192.168.0.3</td><td>graphd, metad-1, storaged-1</td><td>k8s-slave</td></tr><tr><td>192.168.0.4</td><td>graphd, metad-2, storaged-2</td><td>k8s-slave</td></tr></tbody></table><h4 id=kubernetes-待部署组件>Kubernetes 待部署组件</h4><ul><li>安装 Helm</li><li>准备本地磁盘，并安装本地卷插件</li><li>安装 nebula 集群</li><li>安装 ingress-controller</li></ul><h3 id=安装-helm>安装 Helm</h3><p>Helm 是 Kubernetes 集群上的包管理工具，类似 CentOS 上的 yum，Ubuntu 上的 apt-get。使用 Helm 可以极大地降低使用 Kubernetes 部署应用的门槛。由于本篇文章不做 Helm 详细介绍，有兴趣的小伙伴可自行阅读<a href=https://www.hi-linux.com/posts/21466.html>《Helm 入门指南》</a></p><h4 id=下载安装helm>下载安装Helm</h4><p>使用下面命令在终端执行即可安装 Helm</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># wget https://get.helm.sh/helm-v3.0.1-linux-amd64.tar.gz</span> 
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># tar -zxvf helm/helm-v3.0.1-linux-amd64.tgz</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># mv linux-amd64/helm /usr/bin/helm</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># chmod +x /usr/bin/helm</span>
</code></pre></div><h4 id=查看-helm-版本>查看 Helm 版本</h4><p>执行 <code>helm version</code> 命令即可查看对应的 Helm 版本，以文本为例，以下为输出结果：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>version.BuildInfo{
    Version:<span style=color:#e6db74>&#34;v3.0.1&#34;</span>, 
    GitCommit:<span style=color:#e6db74>&#34;7c22ef9ce89e0ebeb7125ba2ebf7d421f3e82ffa&#34;</span>, 
    GitTreeState:<span style=color:#e6db74>&#34;clean&#34;</span>, 
    GoVersion:<span style=color:#e6db74>&#34;go1.13.4&#34;</span>
}
</code></pre></div><h3 id=设置本地磁盘>设置本地磁盘</h3><p>在每台机器上做如下配置</p><h4 id=创建-mount-目录>创建 mount 目录</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mkdir -p /mnt/disks</span>
</code></pre></div><h4 id=格式化数据盘>格式化数据盘</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mkfs.ext4 /dev/diskA</span> 
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mkfs.ext4 /dev/diskB</span>
</code></pre></div><h4 id=挂载数据盘>挂载数据盘</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># DISKA_UUID=$(blkid -s UUID -o value /dev/diskA)</span> 
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># DISKB_UUID=$(blkid -s UUID -o value /dev/diskB)</span> 
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mkdir /mnt/disks/$DISKA_UUID</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mkdir /mnt/disks/$DISKB_UUID</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mount -t ext4 /dev/diskA /mnt/disks/$DISKA_UUID</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo mount -t ext4 /dev/diskB /mnt/disks/$DISKB_UUID</span>

<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># echo UUID=`sudo blkid -s UUID -o value /dev/diskA` /mnt/disks/$DISKA_UUID ext4 defaults 0 2 | sudo tee -a /etc/fstab</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># echo UUID=`sudo blkid -s UUID -o value /dev/diskB` /mnt/disks/$DISKB_UUID ext4 defaults 0 2 | sudo tee -a /etc/fstab</span>
</code></pre></div><h3 id=部署本地卷插件>部署本地卷插件</h3><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># curl https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner/archive/v2.3.3.zip</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># unzip v2.3.3.zip</span>
</code></pre></div><p>修改 v2.3.3/helm/provisioner/values.yaml</p><pre><code>#
# Common options.
#
common:
  #
  # Defines whether to generate service account and role bindings.
  #
  rbac: true
  #
  # Defines the namespace where provisioner runs
  #
  namespace: default
  #
  # Defines whether to create provisioner namespace
  #
  createNamespace: false
  #
  # Beta PV.NodeAffinity field is used by default. If running against pre-1.10
  # k8s version, the `useAlphaAPI` flag must be enabled in the configMap.
  #
  useAlphaAPI: false
  #
  # Indicates if PVs should be dependents of the owner Node.
  #
  setPVOwnerRef: false
  #
  # Provisioner clean volumes in process by default. If set to true, provisioner
  # will use Jobs to clean.
  #
  useJobForCleaning: false
  #
  # Provisioner name contains Node.UID by default. If set to true, the provisioner
  # name will only use Node.Name.
  #
  useNodeNameOnly: false
  #
  # Resync period in reflectors will be random between minResyncPeriod and
  # 2*minResyncPeriod. Default: 5m0s.
  #
  #minResyncPeriod: 5m0s
  #
  # Defines the name of configmap used by Provisioner
  #
  configMapName: &quot;local-provisioner-config&quot;
  #
  # Enables or disables Pod Security Policy creation and binding
  #
  podSecurityPolicy: false
#
# Configure storage classes.
#
classes:
- name: fast-disks # Defines name of storage classe.
  # Path on the host where local volumes of this storage class are mounted
  # under.
  hostDir: /mnt/fast-disks
  # Optionally specify mount path of local volumes. By default, we use same
  # path as hostDir in container.
  # mountDir: /mnt/fast-disks
  # The volume mode of created PersistentVolume object. Default to Filesystem
  # if not specified.
  volumeMode: Filesystem
  # Filesystem type to mount.
  # It applies only when the source path is a block device,
  # and desire volume mode is Filesystem.
  # Must be a filesystem type supported by the host operating system.
  fsType: ext4
  blockCleanerCommand:
  #  Do a quick reset of the block device during its cleanup.
  #  - &quot;/scripts/quick_reset.sh&quot;
  #  or use dd to zero out block dev in two iterations by uncommenting these lines
  #  - &quot;/scripts/dd_zero.sh&quot;
  #  - &quot;2&quot;
  # or run shred utility for 2 iteration.s
     - &quot;/scripts/shred.sh&quot;
     - &quot;2&quot;
  # or blkdiscard utility by uncommenting the line below.
  #  - &quot;/scripts/blkdiscard.sh&quot;
  # Uncomment to create storage class object with default configuration.
  # storageClass: true
  # Uncomment to create storage class object and configure it.
  # storageClass:
    # reclaimPolicy: Delete # Available reclaim policies: Delete/Retain, defaults: Delete.
    # isDefaultClass: true # set as default class

#
# Configure DaemonSet for provisioner.
#
daemonset:
  #
  # Defines the name of a Provisioner
  #
  name: &quot;local-volume-provisioner&quot;
  #
  # Defines Provisioner's image name including container registry.
  #
  image: quay.io/external_storage/local-volume-provisioner:v2.3.3
  #
  # Defines Image download policy, see kubernetes documentation for available values.
  #
  #imagePullPolicy: Always
  #
  # Defines a name of the service account which Provisioner will use to communicate with API server.
  #
  serviceAccount: local-storage-admin
  #
  # Defines a name of the Pod Priority Class to use with the Provisioner DaemonSet
  #
  # Note that if you want to make it critical, specify &quot;system-cluster-critical&quot;
  # or &quot;system-node-critical&quot; and deploy in kube-system namespace.
  # Ref: https://k8s.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/#marking-pod-as-critical
  #
  #priorityClassName: system-node-critical
  # If configured, nodeSelector will add a nodeSelector field to the DaemonSet PodSpec.
  #
  # NodeSelector constraint for local-volume-provisioner scheduling to nodes.
  # Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  #
  # If configured KubeConfigEnv will (optionally) specify the location of kubeconfig file on the node.
  #  kubeConfigEnv: KUBECONFIG
  #
  # List of node labels to be copied to the PVs created by the provisioner in a format:
  #
  #  nodeLabels:
  #    - failure-domain.beta.kubernetes.io/zone
  #    - failure-domain.beta.kubernetes.io/region
  #
  # If configured, tolerations will add a toleration field to the DaemonSet PodSpec.
  #
  # Node tolerations for local-volume-provisioner scheduling to nodes with taints.
  # Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  #
  # If configured, resources will set the requests/limits field to the Daemonset PodSpec.
  # Ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  resources: {}
#
# Configure Prometheus monitoring
#
prometheus:
  operator:
    ## Are you using Prometheus Operator?
    enabled: false

    serviceMonitor:
      ## Interval at which Prometheus scrapes the provisioner
      interval: 10s

      # Namespace Prometheus is installed in
      namespace: monitoring

      ## Defaults to whats used if you follow CoreOS [Prometheus Install Instructions](https://github.com/coreos/prometheus-operator/tree/master/helm#tldr)
      ## [Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/prometheus/templates/prometheus.yaml#L65)
      ## [Kube Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/kube-prometheus/values.yaml#L298)
      selector:
        prometheus: kube-prometheus
</code></pre><p>将<code>hostDir: /mnt/fast-disks</code> 改成<code>hostDir: /mnt/disks</code>将<code># storageClass: true</code> 改成 <code>storageClass: true</code>然后执行：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e>#安装</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># helm install local-static-provisioner v2.3.3/helm/provisioner</span>
<span style=color:#75715e>#查看local-static-provisioner部署情况</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># helm list</span>
</code></pre></div><h3 id=部署-nebula-集群>部署 nebula 集群</h3><h4 id=下载-nebula-helm-chart-包>下载 nebula helm-chart 包</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># 下载nebula</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># wget https://github.com/vesoft-inc/nebula/archive/master.zip</span> 
<span style=color:#75715e># 解压</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># unzip master.zip</span> 
</code></pre></div><h4 id=设置-kubernetes-slave-节点>设置 Kubernetes slave 节点</h4><p>下面是 Kubernetes 节点列表，我们需要设置 slave 节点的调度标签。可以将 <em>192.168.0.2</em>，<em>192.168.0.3</em>，<em>192.168.0.4</em> 打上 nebula: &ldquo;yes&rdquo; 的标签。</p><table><thead><tr><th>服务器 IP</th><th>kubernetes roles</th><th>nodeName</th></tr></thead><tbody><tr><td>192.168.0.1</td><td>master</td><td>192.168.0.1</td></tr><tr><td>192.168.0.2</td><td>worker</td><td>192.168.0.2</td></tr><tr><td>192.168.0.3</td><td>worker</td><td>192.168.0.3</td></tr><tr><td>192.168.0.4</td><td>worker</td><td>192.168.0.4</td></tr></tbody></table><p>具体操作如下：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl  label node 192.168.0.2 nebula=&#34;yes&#34; --overwrite</span> 
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl  label node 192.168.0.3 nebula=&#34;yes&#34; --overwrite</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl  label node 192.168.0.4 nebula=&#34;yes&#34; --overwrite</span>
</code></pre></div><h4 id=调整-nebula-helm-chart-默认的-values-值>调整 nebula helm chart 默认的 values 值</h4><p>nebula helm-chart 包目录如下:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>master/kubernetes/
└── helm
    ├── Chart.yaml
    ├── templates
    │   ├── configmap.yaml
    │   ├── deployment.yaml
    │   ├── _helpers.tpl
    │   ├── ingress-configmap.yaml<span style=color:#ae81ff>\ </span>
    │   ├── NOTES.txt
    │   ├── pdb.yaml
    │   ├── service.yaml
    │   └── statefulset.yaml
    └── values.yaml

<span style=color:#ae81ff>2</span> directories, <span style=color:#ae81ff>10</span> files
</code></pre></div><p>我们需要调整 <code>master/kubernetes/values.yaml</code>  里面的 MetadHosts 的值，将这个 IP List 替换本环境的 3 个 k8s worker 的 ip。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#66d9ef>MetadHosts</span>:
  - <span style=color:#ae81ff>192.168.0.2</span>:<span style=color:#ae81ff>44500</span>
  - <span style=color:#ae81ff>192.168.0.3</span>:<span style=color:#ae81ff>44500</span>
  - <span style=color:#ae81ff>192.168.0.4</span>:<span style=color:#ae81ff>44500</span>
</code></pre></div><h4 id=通过-helm-安装-nebula>通过 helm 安装 nebula</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># 安装</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># helm install nebula master/kubernetes/helm</span> 
<span style=color:#75715e># 查看</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># helm status nebula</span>
<span style=color:#75715e># 查看k8s集群上nebula部署情况</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod  | grep nebula</span>
nebula-graphd-579d89c958-g2j2c                   1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-graphd-579d89c958-p7829                   1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-graphd-579d89c958-q74zx                   1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-metad-0                                   1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-metad-1                                   1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-metad-2                                   1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-storaged-0                                1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-storaged-1                                1/1     Running            <span style=color:#ae81ff>0</span>          1m
nebula-storaged-2                                1/1     Running            <span style=color:#ae81ff>0</span>          1m
</code></pre></div><h3 id=部署-ingress-controller>部署 Ingress-controller</h3><p>Ingress-controller 是 Kubernetes 的一个 Add-Ons。Kubernetes 通过 ingress-controller 将 Kubernetes 内部署的服务暴露给外部用户访问。Ingress-controller 还提供负载均衡的功能，可以将外部访问流量平摊给 k8s 中应用的不同的副本。</p><p><img src=https://nebula-blog.azureedge.net/nebula-blog/k8s02.png alt></p><h3 id=选择一个节点部署-ingress-controller>选择一个节点部署 Ingress-controller</h3><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get node</span> 
NAME              STATUS     ROLES    AGE   VERSION
192.168.0.1       Ready      master   82d   v1.16.1
192.168.0.2       Ready      &lt;none&gt;   82d   v1.16.1
192.168.0.3       Ready      &lt;none&gt;   82d   v1.16.1
192.168.0.4       Ready      &lt;none&gt;   82d   v1.16.1
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl label node 192.168.0.4 ingress=yes</span>
</code></pre></div><p>编写 ingress-nginx.yaml 部署文件</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-configuration
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: tcp-services
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: udp-services
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nginx-ingress-serviceaccount
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: nginx-ingress-clusterrole
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
rules:
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
    verbs:
      - list
      - watch
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - <span style=color:#e6db74>&#34;extensions&#34;</span>
      - <span style=color:#e6db74>&#34;networking.k8s.io&#34;</span>
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - <span style=color:#e6db74>&#34;extensions&#34;</span>
      - <span style=color:#e6db74>&#34;networking.k8s.io&#34;</span>
    resources:
      - ingresses/status
    verbs:
      - update
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: nginx-ingress-role
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
rules:
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - configmaps
      - pods
      - secrets
      - namespaces
    verbs:
      - get
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - configmaps
    resourceNames:
      <span style=color:#75715e># Defaults to &#34;&lt;election-id&gt;-&lt;ingress-class&gt;&#34;</span>
      <span style=color:#75715e># Here: &#34;&lt;ingress-controller-leader&gt;-&lt;nginx&gt;&#34;</span>
      <span style=color:#75715e># This has to be adapted if you change either parameter</span>
      <span style=color:#75715e># when launching the nginx-ingress-controller.</span>
      - <span style=color:#e6db74>&#34;ingress-controller-leader-nginx&#34;</span>
    verbs:
      - get
      - update
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - <span style=color:#e6db74>&#34;&#34;</span>
    resources:
      - endpoints
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: nginx-ingress-role-nisa-binding
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: nginx-ingress-role
subjects:
  - kind: ServiceAccount
    name: nginx-ingress-serviceaccount
    namespace: ingress-nginx

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: nginx-ingress-clusterrole-nisa-binding
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nginx-ingress-clusterrole
subjects:
  - kind: ServiceAccount
    name: nginx-ingress-serviceaccount
    namespace: ingress-nginx

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
      annotations:
        prometheus.io/port: <span style=color:#e6db74>&#34;10254&#34;</span>
        prometheus.io/scrape: <span style=color:#e6db74>&#34;true&#34;</span>
    spec:
      hostNetwork: true
      tolerations:
        - key: <span style=color:#e6db74>&#34;node-role.kubernetes.io/master&#34;</span>
          operator: <span style=color:#e6db74>&#34;Exists&#34;</span>
          effect: <span style=color:#e6db74>&#34;NoSchedule&#34;</span>
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app.kubernetes.io/name
                    operator: In
                    values:
                      - ingress-nginx
              topologyKey: <span style=color:#e6db74>&#34;ingress-nginx.kubernetes.io/master&#34;</span>
      nodeSelector:
        ingress: <span style=color:#e6db74>&#34;yes&#34;</span>
      serviceAccountName: nginx-ingress-serviceaccount
      containers:
        - name: nginx-ingress-controller
          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller-amd64:0.26.1
          args:
            - /nginx-ingress-controller
            - --configmap<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>POD_NAMESPACE<span style=color:#66d9ef>)</span>/nginx-configuration
            - --tcp-services-configmap<span style=color:#f92672>=</span>default/graphd-services
            - --udp-services-configmap<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>POD_NAMESPACE<span style=color:#66d9ef>)</span>/udp-services
            - --publish-service<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>POD_NAMESPACE<span style=color:#66d9ef>)</span>/ingress-nginx
            - --annotations-prefix<span style=color:#f92672>=</span>nginx.ingress.kubernetes.io
            - --http-port<span style=color:#f92672>=</span><span style=color:#ae81ff>8000</span>
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
                - ALL
              add:
                - NET_BIND_SERVICE
            <span style=color:#75715e># www-data -&gt; 33</span>
            runAsUser: <span style=color:#ae81ff>33</span>
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http
              containerPort: <span style=color:#ae81ff>80</span>
            - name: https
              containerPort: <span style=color:#ae81ff>443</span>
          livenessProbe:
            failureThreshold: <span style=color:#ae81ff>3</span>
            httpGet:
              path: /healthz
              port: <span style=color:#ae81ff>10254</span>
              scheme: HTTP
            initialDelaySeconds: <span style=color:#ae81ff>10</span>
            periodSeconds: <span style=color:#ae81ff>10</span>
            successThreshold: <span style=color:#ae81ff>1</span>
            timeoutSeconds: <span style=color:#ae81ff>10</span>
          readinessProbe:
            failureThreshold: <span style=color:#ae81ff>3</span>
            httpGet:
              path: /healthz
              port: <span style=color:#ae81ff>10254</span>
              scheme: HTTP
            periodSeconds: <span style=color:#ae81ff>10</span>
            successThreshold: <span style=color:#ae81ff>1</span>
            timeoutSeconds: <span style=color:#ae81ff>10</span>
</code></pre></div><p>部署 ingress-nginx</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># 部署</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl create -f ingress-nginx.yaml</span>
<span style=color:#75715e># 查看部署情况</span>
<span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod -n ingress-nginx</span> 
NAME                             READY   STATUS    RESTARTS   AGE
nginx-ingress-controller-mmms7   1/1     Running   <span style=color:#ae81ff>2</span>          1m
</code></pre></div><h3 id=访问-nebula-集群>访问 nebula 集群</h3><p>查看 ingress-nginx 所在的节点：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get node -l ingress=yes -owide</span> 
NAME            STATUS   ROLES    AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION          CONTAINER-RUNTIME
192.168.0.4     Ready    &lt;none&gt;   1d   v1.16.1    192.168.0.4    &lt;none&gt;        CentOS Linux <span style=color:#ae81ff>7</span> <span style=color:#f92672>(</span>Core<span style=color:#f92672>)</span>   7.6.1810.el7.x86_64     docker://19.3.3
</code></pre></div><p>访问 nebula 集群:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>[</span>root@nebula ~<span style=color:#f92672>]</span><span style=color:#75715e># docker run --rm -ti --net=host vesoft/nebula-console:nightly --addr=192.168.0.4 --port=3699</span>
</code></pre></div><h2 id=faq>FAQ</h2><blockquote><p>如何搭建一套 Kubernetes 集群？</p></blockquote><p>搭建高可用的 Kubernetes 可以参考社区文档：<a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/>https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</a></p><p>你也可以通过 minikube 搭建本地的 Kubernetes 集群，参考文档：<a href=https://kubernetes.io/docs/setup/learning-environment/minikube/>https://kubernetes.io/docs/setup/learning-environment/minikube/</a></p><blockquote><p>如何调整 nebula 集群的部署参数?</p></blockquote><p>在使用 helm install 时，使用 &ndash;set 可以设置部署参数，从而覆盖掉 helm chart 中 values.yaml 中的变量。参考文档：<a href=https://helm.sh/docs/intro/using_helm/>https://helm.sh/docs/intro/using_helm/</a></p><blockquote><p>如何查看 nebula 集群状况？</p></blockquote><p>使用<code>kubectl get pod | grep nebula</code>命令，或者直接在 Kubernetes dashboard 上查看 nebula 集群的运行状况。</p><blockquote><p>如何使用其他类型的存储？</p></blockquote><p>参考文档：<a href=https://kubernetes.io/zh/docs/concepts/storage/storage-classes/>https://kubernetes.io/zh/docs/concepts/storage/storage-classes/</a></p><h2 id=参考资料>参考资料</h2><ul><li><a href=https://www.hi-linux.com/posts/21466.html>Helm 入门指南</a></li><li><a href=http://www.aieve.cn/article/1571726983727>详解 k8s 组件 Ingress 边缘路由器并落地到微服务</a></li></ul><h2 id=附录>附录</h2><ul><li>Nebula Graph：一个开源的分布式图数据库</li><li>GitHub：<a href=https://github.com/vesoft-inc/nebula>https://github.com/vesoft-inc/nebula</a></li><li>知乎：<a href=https://www.zhihu.com/org/nebulagraph/posts>zhihu.com/org/nebulagraph/posts</a></li><li>微博：<a href=https://weibo.com/nebulagraph>weibo.com/nebulagraph</a></li></ul><h2 id=推荐阅读>推荐阅读</h2><ul><li><a href=https://nebula-graph.io/cn/posts/how-indexing-works-in-nebula-graph/>分布式图数据库 Nebula Graph 的 Index 实践</a></li><li><a href=https://nebula-graph.io/cn/posts/clean-stale-data-with-ttl-in-nebula-graph/>图数据库 Nebula Graph TTL 特性</a></li></ul><blockquote class=star-ads><span>你喜欢这篇文章吗? 喜欢的话，给我们点个</span>
<span class="glyphicon glyphicon-star"></span><span>star 吧:</span>
<a href=https://github.com/vesoft-inc/nebula>https://github.com/vesoft-inc/nebula</a></blockquote><ul class=blog-footer><li><img src=/images/tag.png>
<a href=/nebula-website/cn/tags/%e9%83%a8%e7%bd%b2>部署</a></li><li class="nebula-share st-btn"><img src=/images/share.png>
<span>分享</span><ul class=blog-footer-share-links><li class=st-custom-button data-network=wechat><img alt="wechat-white sharing button" src=https://platform-cdn.sharethis.com/img/wechat-white.svg>
<span class=st-label>微信</span></li><li class=st-custom-button data-network=weibo><img alt="weibo-white sharing button" src=https://platform-cdn.sharethis.com/img/weibo-white.svg>
<span class=st-label>微博</span></li><li class=st-custom-button data-network=sharethis><img alt="sharethis-white sharing button" src=https://platform-cdn.sharethis.com/img/sharethis-white.svg>
<span class=st-label>其他</span></li></ul></li><li onclick="location.href='\/nebula-website\/cn\/posts'"><img src=/images/blog.png>
<a href=/nebula-website/cn/posts>返回到博客页</a></li><li onclick="location.href='https:\/\/nebula-graph.io/cn/posts/index.xml'"><img src=/images/rss.png>
<a onclick="window.open('https:\/\/nebula-graph.io/cn/posts/index.xml')" href>RSS</a></li></ul><div id=discourse-comments></div></section><div class=single-side-bar><div class=tags-block><h3 class="glyphicon glyphicon-tag">标签</h3><ul class=blog-tags><li class=col-md-12><a href=/nebula-website/cn/posts class=active>全部</a></li><li><a href=/nebula-website/cn/tags/release-note>release-note</a></li><li><a href=/nebula-website/cn/tags/%E4%BA%A7%E5%93%81%E5%8A%A8%E6%80%81>产品动态</a></li><li><a href=/nebula-website/cn/tags/%E4%BA%A7%E5%93%81%E8%AE%B2%E8%A7%A3>产品讲解</a></li><li><a href=/nebula-website/cn/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86>图数据库知识</a></li><li><a href=/nebula-website/cn/tags/%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5>应用实践</a></li><li><a href=/nebula-website/cn/tags/%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97>开发日志</a></li><li><a href=/nebula-website/cn/tags/%E6%80%A7%E8%83%BD>性能</a></li><li><a href=/nebula-website/cn/tags/%E6%8A%80%E6%9C%AF%E6%BC%94%E8%AE%B2>技术演讲</a></li><li><a href=/nebula-website/cn/tags/%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90>架构剖析</a></li><li><a href=/nebula-website/cn/tags/%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80>查询语言</a></li><li><a href=/nebula-website/cn/tags/%E7%89%B9%E6%80%A7%E8%AE%B2%E8%A7%A3>特性讲解</a></li><li><a href=/nebula-website/cn/tags/%E7%A4%BE%E5%8C%BA>社区</a></li><li><a href=/nebula-website/cn/tags/%E7%B3%BB%E7%BB%9F%E6%B5%8B%E8%AF%95>系统测试</a></li><li><a href=/nebula-website/cn/tags/%E7%BC%96%E8%AF%91>编译</a></li><li><a href=/nebula-website/cn/tags/%E9%83%A8%E7%BD%B2>部署</a></li></ul></div><div id=blog-carousel class="carousel slide" data-ride=carousel><ol class=carousel-indicators><li data-target=#blog-carousel data-slide-to=0 class=active></li><li data-target=#blog-carousel data-slide-to=1></li></ol><div class=carousel-inner role=listbox><div class="item active" onclick="location.href='\/cn\/posts\/clean-stale-data-with-ttl-in-nebula-graph\/'"><img src=https://nebula-blog.azureedge.net/nebula-blog/TTL01.png alt="TTL 特性讲解" width=220px height=150px><div class=carousel-caption>TTL 特性讲解</div></div><div class=item onclick="location.href='\/cn\/posts\/github-action-automating-project-process\/'"><img src=https://nebula-blog.azureedge.net/nebula-blog/Action01.png alt="Action 自动化发布" width=220px height=150px><div class=carousel-caption>Action 自动化发布</div></div></div><a class="left carousel-control" href=#blog-carousel role=button data-slide=prev><span class="glyphicon glyphicon-chevron-left" aria-hidden=true></span><span class=sr-only>Previous</span></a>
<a class="right carousel-control" href=#blog-carousel role=button data-slide=next><span class="glyphicon glyphicon-chevron-right" aria-hidden=true></span><span class=sr-only>Next</span></a></div><div class=blog-anchors><h3>目录</h3><nav id=TableOfContents><ul><li><a href=#kubernetes-是什么>Kubernetes 是什么</a></li><li><a href=#kubernetes-和数据库>Kubernetes 和数据库</a></li><li><a href=#nebula-graph在kubernetes中的实践>Nebula Graph在Kubernetes中的实践</a><ul><li><a href=#集群部署>集群部署</a></li><li><a href=#安装-helm>安装 Helm</a></li><li><a href=#设置本地磁盘>设置本地磁盘</a></li><li><a href=#部署本地卷插件>部署本地卷插件</a></li><li><a href=#部署-nebula-集群>部署 nebula 集群</a></li><li><a href=#部署-ingress-controller>部署 Ingress-controller</a></li><li><a href=#选择一个节点部署-ingress-controller>选择一个节点部署 Ingress-controller</a></li><li><a href=#访问-nebula-集群>访问 nebula 集群</a></li></ul></li><li><a href=#faq>FAQ</a></li><li><a href=#参考资料>参考资料</a></li><li><a href=#附录>附录</a></li><li><a href=#推荐阅读>推荐阅读</a></li></ul></nav></div><div class=social-share><h3>分享</h3><div class=nebula-share-buttons><div class="st-custom-button st-remove-label" data-network=wechat><img alt="wechat-white sharing button" src=https://platform-cdn.sharethis.com/img/wechat-white.svg></div><div class="st-custom-button st-remove-label" data-network=weibo><img alt="weibo-white sharing button" src=https://platform-cdn.sharethis.com/img/weibo-white.svg></div><div class="st-custom-button st-remove-label" data-network=twitter><img alt="twitter-white sharing button" src=https://platform-cdn.sharethis.com/img/twitter-white.svg></div><div class="st-custom-button st-remove-label" data-network=linkedin><img alt="linkedin-white sharing button" src=https://platform-cdn.sharethis.com/img/linkedin-white.svg></div><div class="st-custom-button st-remove-label" data-network=facebook><img alt="facebook-white sharing button" src=https://platform-cdn.sharethis.com/img/facebook-white.svg></div><div class="st-custom-button st-remove-label" data-network=hackernews><img alt="hackernews-white sharing button" src=https://platform-cdn.sharethis.com/img/hackernews-white.svg></div><div class="st-custom-button st-remove-label" data-network=reddit><img alt="reddit-white sharing button" src=https://platform-cdn.sharethis.com/img/reddit-white.svg></div><div class="st-custom-button st-remove-label" data-network=sharethis><img alt="reddit-white sharing button" src=https://platform-cdn.sharethis.com/img/sharethis-white.svg></div></div></div></div></div><img onclick="location.href='#top'" class=go-ahead src=/images/up.png></div><footer class="container-fluid foot-wrap" name=contact_us><div class=container><p align=center class=statement>Nebula Graph will respect your data privacy per our Privacy Policy</p><div class=row><div class="row-content col-lg-4 col-sm-4 col-xs-4"><h3>Community</h3><ul><li><img src=/img/github.png>
<a href=https://github.com/vesoft-inc/nebula target=_blank>GitHub</a></li><li><img src=/img/forum.png>
<a href=https://discuss.nebula-graph.io/ target=_blank>论坛</a></li><li><img src=/img/slack.png>
<a href=https://join.slack.com/t/nebulagraph/shared_invite/enQtNjIzMjQ5MzE2OTQ2LTM0MjY0MWFlODg3ZTNjMjg3YWU5ZGY2NDM5MDhmOGU2OWI5ZWZjZDUwNTExMGIxZTk2ZmQxY2Q2MzM1OWJhMmY# target=_blank>Slack</a></li></ul></div><div class="row-content col-lg-4 col-sm-4 col-xs-4"><h3>Follow Us</h3><ul><li><img src=/img/twitter.png>
<a href=https://twitter.com/NebulaGraph title=Twitter data-toggle=modal target=_blank data-target>Twitter</a></li><li><img src=/img/weibo.png>
<a href=https://weibo.com/nebulagraph title=微博 data-toggle=modal target=_blank data-target>微博</a></li><li><img src=/img/linkedin.png>
<a href=https://www.linkedin.com/company/vesoft-nebula-graph/ title=LinkedIn data-toggle=modal target=_blank data-target>LinkedIn</a></li><li><img src=/img/youtube.png>
<a href=https://www.youtube.com/channel/UC73V8q795eSEMxDX4Pvdwmw title=YouTube data-toggle=modal target=_blank data-target>YouTube</a></li><li><img src=/img/facebook.png>
<a href=https://www.facebook.com/NebulaGraph/ title=FaceBook data-toggle=modal target=_blank data-target>FaceBook</a></li><li><img src=/img/gongzhonghao.png>
<a href title=微信公众号 data-toggle=modal target=_blank data-target=#myGongzhonghaoModal>微信公众号</a></li></ul></div><div class="contactus row-content col-lg-4 col-sm-4 col-xs-4"><h3>Contact Us</h3><ul><li><img src=/img/iphone.png>
<a href data-toggle=modal target=_blank data-target>(+86) 0571-28120658</a></li><li><img src=/img/email.png>
<a href=mailto:info@vesoft.com data-toggle=modal target=_blank data-target>info@vesoft.com</a></li><li><img src=/img/weixin.png>
<a href data-toggle=modal target=_blank data-target=#myModal>微信个人助理</a></li></ul></div></div></div><p align=left style=font-size:16px><img src=/images/VEsoft.png style=margin-right:10px> Copyright &copy;2020 VESoft Inc</p><div class="modal fade" id=myGongzhonghaoModal tabindex=-1 role=dialog aria-labelledby=myModalLabel aria-hidden=true><div class=modal-dialog><div class=modal-content><div class="modal-body wechat"><img src=/images/gonggonghaoCODE.jpg></div><div class=modal-footer><button type=button class="btn btn-default" data-dismiss=modal>close</button></div></div></div></div><div class="modal fade" id=myModal tabindex=-1 role=dialog aria-labelledby=myModalLabel aria-hidden=true><div class=modal-dialog><div class=modal-content><div class="modal-body wechat"><img src=/images/wechat.png></div><div class=modal-footer><button type=button class="btn btn-default" data-dismiss=modal>close</button></div></div></div></div></footer></main><div id=J-star-popup class=nebula-star-popup></div><script src=/nebula-website/js/jquery.js></script><script src=/nebula-website/js/bootstrap.min.js></script><script src=/nebula-website/js/jquery.easing.min.js></script><script src=/nebula-website/js/jquery.fittext.js></script><script src=/nebula-website/js/wow.min.js></script><script type=text/javascript src="https://platform-api.sharethis.com/js/sharethis.js#property=5e7c2cc315c7990012ae38bc&product=inline-share-buttons" async></script><script src=/nebula-website/js/creative.js></script><script async defer src=https://buttons.github.io/buttons.js></script><script src=/nebula-website/js/init.js></script><script type=text/javascript>DiscourseEmbed={discourseUrl:'https://discuss.nebula-graph.io/',discourseEmbedUrl:"\/nebula-website\/cn\/posts\/how-to-deploy-nebula-graph-in-kubernetes\/"};(function(){var d=document.createElement('script');d.type='text/javascript';d.async=true;d.src=DiscourseEmbed.discourseUrl+'javascripts/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(d);})();</script></body></html>